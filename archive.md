---
layout: default
---
# Archive

See below for links to materials for previous tutorials.

| Tutorial| Description| Leader| Code| Video| Slides|
|---|---|---|---|---|---|
| Comparing Word Embedding Models| We'll demonstrate an extension of the use of word embedding models by fitting multiple models on a social science corpus (using gensim's word2vec implementation), then aligning and comparing those models. This method is used to explore group variation and temporal change. We'll discuss some tradeoffs and possible extensions of this approach.| [Connor Gilroy](https://ccgilroy.com/), [Sandeep Soni](https://sandeepsoni.github.io/) | [link](https://colab.research.google.com/drive/16cM5NXedlrvU2mp-HcYKs9OIMkYItTS1?usp=sharing) | [link](https://youtu.be/WbzPZZKJRJA)| N/A|
| Extracting Information from Documents| This workshop provides an introduction to information extraction for social scienceâ€“techniques for identifying specific words, phrases, or pieces of information contained within documents. It focuses on two common techniques, named entity recognition and dependency parses, and shows how they can provide useful descriptive data about the civil war in Syria. The workshop uses the Python library spaCy, but no previous experience is needed beyond familiarity with Python.| [Andrew Halterman](https://www.andrewhalterman.com/)| [link](https://colab.research.google.com/drive/1U6x-3OVCGtx9CBZvzdJi8mhTxCx8k4Ie?usp=sharing) | [link](https://youtu.be/sUtthdcPyhc)| N/A|
| Controlling for Text in Causal Inference with Double Machine Learning| Establishing causal relationships is a fundamental goal of scientific research. Text plays an increasingly important role in the study of causal relationships across domains especially for observational (non-experimental) data. Specifically, text can serve as a valuable "control" to eliminate the effects of variables that threaten the validity of the causal inference process. But how does one control for text, an unstructured and nebulous quantity? In this tutorial, we will learn about bias from confounding, motivation for using text as a proxy for confounders, apply a "double machine learning" framework that uses text to remove confounding bias, and compare this framework with non-causal text dimensionality reduction alternatives such as topic modeling. | [Emaad Manzoor](https://emaadmanzoor.com/)| [link](https://colab.research.google.com/drive/15Jz9QehJsT2um1cH5GEbbBOeJDcX0e2n?usp=sharing) | [link](https://youtu.be/DwUqA1ydJI0)| [link](docs/NLP+CSS201 - Controlling for Text in Causal Inference.pdf)|
| Beyond the Bag Of Words: Text Analysis with Contextualized Topic Models | Most topic models still use Bag-Of-Words (BoW) document representations as input. These representations, though, disregard the syntactic and semantic relationships among the words in a document, the two main linguistic avenues to coherent text. Recently, pre-trained contextualized embeddings have enabled exciting new results in several NLP tasks, mapping a sentence to a vector representation. Contextualized Topic Models (CTM) combine contextualized embeddings with neural topic models to increase the quality of the topics. Moreover, using multilingual embeddings allows the model to learn topics in one language and predict them for documents in unseen languages, thus addressing a task of zero-shot cross-lingual topic modeling.|  [Silvia Terragni](https://silviatti.github.io/)| [link](https://colab.research.google.com/drive/1EO0bS0Wow_cjdGsDfV38xt--AxJQjFtg?usp=sharing) | [link](https://www.youtube.com/watch?v=n1_G8K07KoM) | N/A|
| BERT for Computational Social Scientists| What is BERT? How do you use it? What kinds of computational social science projects would BERT be most useful for? Join for a conceptual overview of this popular natural language processing (NLP) model as well as a hands-on, code-based tutorial that demonstrates how to train and fine-tune a BERT model using HuggingFace's popular Python library.| [Maria Antoniak](https://maria-antoniak.github.io/)| [link](https://colab.research.google.com/drive/1ih6ETBCU2Dqr1_aTPgjS_Ww3xXVswIO0?usp=sharing) | [link](https://youtu.be/UmyOhl9AciI)| [link](https://docs.google.com/presentation/d/1HGWnLkv7_2fST9tFVbvQbY-rN4aTMjJW/) |
